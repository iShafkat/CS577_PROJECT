{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xU-eMjCpwp2D"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "from keras_tuner import RandomSearch\n",
        "import numpy as np \n",
        "import random\n",
        "import pandas as pd \n",
        "from keras.layers import (LSTM,Embedding,BatchNormalization,Dense,TimeDistributed,Dropout,Bidirectional,Flatten,GlobalMaxPool1D,GlobalAveragePooling1D,MultiHeadAttention,LayerNormalization,SimpleRNN)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from plotly import graph_objs as go\n",
        "import plotly.express as px\n",
        "import plotly.figure_factory as ff\n",
        "from plotly.offline import iplot\n",
        "from PIL import Image\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "import nltk\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.initializers import Constant\n",
        "from keras.layers import (LSTM, \n",
        "                          Embedding, \n",
        "                          BatchNormalization,\n",
        "                          Dense, \n",
        "                          TimeDistributed, \n",
        "                          Dropout, \n",
        "                          Bidirectional,\n",
        "                          Flatten, \n",
        "                          GlobalMaxPool1D)\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.metrics import (\n",
        "    precision_score, \n",
        "    recall_score, \n",
        "    f1_score, \n",
        "    classification_report,\n",
        "    accuracy_score\n",
        ")\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from keras.utils import pad_sequences\n",
        "from sklearn import metrics\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
        "from keras.models import Model\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "from keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "r0JUIsj6xx4n",
        "outputId": "400762a7-e9ae-4859-ebfe-ef860aa07e2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4e75e8b1-6c90-45f7-823a-8c1540403dd3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4e75e8b1-6c90-45f7-823a-8c1540403dd3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving spam.csv to spam (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"spam.csv\", delimiter=',',encoding='latin-1')\n",
        "df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'],axis=1,inplace=True)\n",
        "df.rename(columns = {\"v1\": \"target\", \"v2\": \"text\"}, inplace = True)\n",
        "x = ['ham', 'spam']\n",
        "y = df.groupby(\"target\")[\"target\"].agg(\"count\").values\n",
        "df['text_len'] = df['text'].apply(lambda x: len(x.split(' ')))"
      ],
      "metadata": {
        "id": "IZdk7S34x0g7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data_plot"
      ],
      "metadata": {
        "id": "2xSlWfhBGRPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layout = go.Layout(title={'text':'Proportional Distribution of the Target Variable',\n",
        "                         'y':0.9,\n",
        "                         'x':0.5,\n",
        "                         'xanchor':'center',\n",
        "                         'yanchor':'top'},\n",
        "                  template = 'plotly_dark')\n",
        "\n",
        "fig = go.Figure(data=[go.Bar(\n",
        "    x = x, y = y,\n",
        "    text = y, textposition = 'auto',\n",
        "    marker_color = \"slateblue\"\n",
        ")], layout = layout)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "6356L1PCyDZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colors = [\"slateblue\", \"darkred\"]\n",
        "\n",
        "fig = go.Figure(data=[go.Pie(labels = df['target'].value_counts().keys(),\n",
        "                             values = df['target'].value_counts().values,\n",
        "                             pull = [0, 0.25])])\n",
        "\n",
        "fig.update_traces(hoverinfo ='label',\n",
        "                  textinfo ='percent',\n",
        "                  textfont_size = 20,\n",
        "                  textposition ='auto',\n",
        "                  marker=dict(colors=colors,\n",
        "                              line = dict(color = 'lightgray',\n",
        "                                          width = 1.5)))\n",
        "fig.update_layout(title={'text': \"Percentages of the Target Values\",\n",
        "                         'y':0.9,\n",
        "                         'x':0.5,\n",
        "                         'xanchor': 'center',\n",
        "                         'yanchor': 'top'},\n",
        "                  template='plotly_dark')\n",
        "\n",
        "iplot(fig)"
      ],
      "metadata": {
        "id": "NyvPyMS-yFkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ham = df[df[\"target\"] == \"ham\"][\"text_len\"].value_counts().sort_index()\n",
        "spam = df[df[\"target\"] == \"spam\"][\"text_len\"].value_counts().sort_index()\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x = ham.index, y = ham.values, name = \"ham\", \n",
        "                         fill = \"tozeroy\"))\n",
        "fig.add_trace(go.Scatter(x = spam.index, y = spam.values, name=\"spam\",\n",
        "                        fill = \"tozeroy\"))\n",
        "fig.update_layout(title={'text': \"Distributions of Target Values\",\n",
        "                         'y':0.9,\n",
        "                         'x':0.5,\n",
        "                         'xanchor': 'center',\n",
        "                         'yanchor': 'top'},\n",
        "                  template='plotly_dark')\n",
        "fig.update_xaxes(range=[0, 50])\n",
        "fig.update_yaxes(range=[0, 450])\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "uG9giV4myMKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "FuE1CuNgyPMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = df['text'].apply(clean_text)\n",
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words(\"english\")\n",
        "df[\"text\"] = df[\"text\"].apply(lambda x: \" \".join(x for x in x.split() if x not in stop_words))\n",
        "stemmer = nltk.SnowballStemmer(\"english\")\n",
        "df[\"text\"] = df[\"text\"].apply(lambda x: \" \".join([stemmer.stem(word) for word in x.split()]))\n",
        "text = \" \".join(i for i in df.text)\n",
        "\n",
        "wc = WordCloud(background_color = \"black\", width = 1200, height = 600,\n",
        "               contour_width = 0, contour_color = \"#410F01\", max_words = 1000,\n",
        "               scale = 1, collocations = False, repeat = True, min_font_size = 1)\n",
        "\n",
        "wc.generate(text)\n",
        "lb = LabelEncoder()\n",
        "df[\"target\"] = lb.fit_transform(df[\"target\"])"
      ],
      "metadata": {
        "id": "bAalDT7yyRkV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "706ef184-66ff-488b-dd2c-65580593e90b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['text']\n",
        "y = df['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "vec = CountVectorizer()\n",
        "vec.fit(X_train)\n",
        "\n",
        "X_train_dtm = vec.transform(X_train)\n",
        "X_test_dtm = vec.transform(X_test)\n",
        "max_words = 1000\n",
        "max_len = 150\n",
        "tok = Tokenizer(num_words=max_words)\n",
        "tok.fit_on_texts(X_train)\n",
        "sequences = tok.texts_to_sequences(X_train)\n",
        "sequences_matrix = pad_sequences(sequences,maxlen=max_len)"
      ],
      "metadata": {
        "id": "hx7EgBbWzPQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test1 = y_test\n",
        "X_test1 = X_test\n",
        "try:\n",
        "  while y_test1[y_test1 == 0].index[0]:\n",
        "    index_30 = y_test1[y_test1 == 0].index[0]\n",
        "    y_test1.drop(index_30, inplace = True)\n",
        "    X_test1.drop(index_30, inplace = True)\n",
        "except: pass\n"
      ],
      "metadata": {
        "id": "fO4BeeGRGEQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def LSTM_model():\n",
        "    inputs = Input(name='inputs',shape=[max_len])\n",
        "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
        "    layer = LSTM(64)(layer)\n",
        "    layer = Dense(256,name='FC1')(layer)\n",
        "    layer = Activation('relu')(layer)\n",
        "    layer = Dropout(0.5)(layer)\n",
        "    layer = Dense(1,name='out_layer')(layer)\n",
        "    layer = Activation('sigmoid')(layer)\n",
        "    model = Model(inputs=inputs,outputs=layer)\n",
        "    return model"
      ],
      "metadata": {
        "id": "BaFP1orkziKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def RNN_model():\n",
        "    inputs = Input(name='inputs',shape=[max_len])\n",
        "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
        "    layer = SimpleRNN(64)(layer)\n",
        "    layer = Dense(256,name='FC1')(layer)\n",
        "    layer = Activation('relu')(layer)\n",
        "    layer = Dropout(0.5)(layer)\n",
        "    layer = Dense(1,name='out_layer')(layer)\n",
        "    layer = Activation('sigmoid')(layer)\n",
        "    model = Model(inputs=inputs,outputs=layer)\n",
        "    return model"
      ],
      "metadata": {
        "id": "9tgMcUrniM0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DNN_model():\n",
        "    inputs = Input(name='inputs',shape=[max_len])\n",
        "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
        "    layer = Dense(64)(layer)\n",
        "    layer = Dense(256,name='FC1')(layer)\n",
        "    layer = Activation('relu')(layer)\n",
        "    layer = Dropout(0.5)(layer)\n",
        "    layer = Dense(1,name='out_layer')(layer)\n",
        "    layer = Activation('sigmoid')(layer)\n",
        "    model = Model(inputs=inputs,outputs=layer)\n",
        "    return model"
      ],
      "metadata": {
        "id": "SPga_HlWIMh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_rnn = RNN_model()\n",
        "model_rnn.summary()\n",
        "model_rnn.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJFB6pQ8Tm_O",
        "outputId": "0407978b-f50a-47ac-daf2-f88f0f171384"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inputs (InputLayer)         [(None, 150)]             0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 150, 50)           50000     \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 64)                7360      \n",
            "                                                                 \n",
            " FC1 (Dense)                 (None, 256)               16640     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " out_layer (Dense)           (None, 1)                 257       \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 74,257\n",
            "Trainable params: 74,257\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_dnn = DNN_model()\n",
        "model_dnn.summary()\n",
        "model_dnn.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kklyAnUIVcyE",
        "outputId": "8dd8a57e-9ab5-4828-b73f-434502c9aa90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inputs (InputLayer)         [(None, 150)]             0         \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, 150, 50)           50000     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 150, 64)           3264      \n",
            "                                                                 \n",
            " FC1 (Dense)                 (None, 150, 256)          16640     \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 150, 256)          0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 150, 256)          0         \n",
            "                                                                 \n",
            " out_layer (Dense)           (None, 150, 1)            257       \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 150, 1)            0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 70,161\n",
            "Trainable params: 70,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_lstm = LSTM_model()\n",
        "model_lstm.summary()\n",
        "model_lstm.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sRHtA_QzkYd",
        "outputId": "ccd4dcbd-1302-4076-a734-6ee054701064"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inputs (InputLayer)         [(None, 150)]             0         \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 150, 50)           50000     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                29440     \n",
            "                                                                 \n",
            " FC1 (Dense)                 (None, 256)               16640     \n",
            "                                                                 \n",
            " activation (Activation)     (None, 256)               0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " out_layer (Dense)           (None, 1)                 257       \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 96,337\n",
            "Trainable params: 96,337\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_lstm.fit(sequences_matrix,y_train,batch_size=128,epochs=10,\n",
        "          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6EFENXszmIb",
        "outputId": "8978e9cf-4021-414d-a618-c53a60340c21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "27/27 [==============================] - 19s 514ms/step - loss: 0.3857 - accuracy: 0.8418 - val_loss: 0.2349 - val_accuracy: 0.9222\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 7s 251ms/step - loss: 0.1405 - accuracy: 0.9593 - val_loss: 0.1059 - val_accuracy: 0.9737\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 8s 308ms/step - loss: 0.0672 - accuracy: 0.9806 - val_loss: 0.0795 - val_accuracy: 0.9809\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 7s 253ms/step - loss: 0.0411 - accuracy: 0.9862 - val_loss: 0.0968 - val_accuracy: 0.9821\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fce4f479ab0>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_rnn.fit(sequences_matrix,y_train,batch_size=128,epochs=10,\n",
        "          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMoYQrmuTurf",
        "outputId": "5787df6b-a787-443e-88fc-ed8866f0fc1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "27/27 [==============================] - 7s 151ms/step - loss: 0.3260 - accuracy: 0.8857 - val_loss: 0.1771 - val_accuracy: 0.9569\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 3s 121ms/step - loss: 0.1664 - accuracy: 0.9279 - val_loss: 0.1036 - val_accuracy: 0.9653\n",
            "Epoch 3/10\n",
            "27/27 [==============================] - 4s 134ms/step - loss: 0.0662 - accuracy: 0.9827 - val_loss: 0.0846 - val_accuracy: 0.9797\n",
            "Epoch 4/10\n",
            "27/27 [==============================] - 5s 209ms/step - loss: 0.0454 - accuracy: 0.9874 - val_loss: 0.1087 - val_accuracy: 0.9593\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fce4c4effd0>"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_dnn.fit(sequences_matrix,y_train,batch_size=128,epochs=10,\n",
        "          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBb-xdmMVlIi",
        "outputId": "57658939-3ac7-46c5-c275-dcc1314e42a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "27/27 [==============================] - 7s 192ms/step - loss: 0.4570 - accuracy: 0.8536 - val_loss: 0.3924 - val_accuracy: 0.8687\n",
            "Epoch 2/10\n",
            "27/27 [==============================] - 4s 154ms/step - loss: 0.3878 - accuracy: 0.8710 - val_loss: 0.3926 - val_accuracy: 0.8701\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fce4f9eeec0>"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sequences = tok.texts_to_sequences(X_test1)\n",
        "test_sequences_matrix = pad_sequences(test_sequences,maxlen=max_len)\n",
        "y_pred_dnn = model_dnn.predict(test_sequences_matrix)\n",
        "\n",
        "accr = model_dnn.evaluate(test_sequences_matrix,y_test1)\n"
      ],
      "metadata": {
        "id": "uMZjWVguVo8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sequences = tok.texts_to_sequences(X_test1)\n",
        "test_sequences_matrix = pad_sequences(test_sequences,maxlen=max_len)\n",
        "y_pred_lstm = model_lstm.predict(test_sequences_matrix)\n",
        "\n",
        "accr = model_lstm.evaluate(test_sequences_matrix,y_test1)\n"
      ],
      "metadata": {
        "id": "rN9M95rPzoeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sequences = tok.texts_to_sequences(X_test1)\n",
        "test_sequences_matrix = pad_sequences(test_sequences,maxlen=max_len)\n",
        "y_pred_rnn = model_rnn.predict(test_sequences_matrix)\n",
        "\n",
        "accr = model_rnn.evaluate(test_sequences_matrix,y_test1)"
      ],
      "metadata": {
        "id": "aAKRBXC7TysM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Define the Transformer model with tunable hyperparameters\n",
        "def build_model(hp):\n",
        "    input_dim = max_words\n",
        "    output_dim = hp.Int('output_dim', min_value=32, max_value=128, step=32)\n",
        "    num_heads = hp.Int('num_heads', min_value=2, max_value=8, step=2)\n",
        "    dff = hp.Int('dff', min_value=32, max_value=128, step=32)\n",
        "    rate = hp.Float('rate', min_value=0.1, max_value=0.5, step=0.1)\n",
        "\n",
        "    inputs = Input(shape=(max_len,))\n",
        "    embedding_layer = Embedding(input_dim, output_dim, input_length=max_len)(inputs)\n",
        "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=output_dim)(embedding_layer, embedding_layer)\n",
        "    attn_output = LayerNormalization(epsilon=1e-6)(embedding_layer + attn_output)\n",
        "    ffn_output = Dense(dff, activation='relu')(attn_output)\n",
        "    ffn_output = Dense(output_dim)(ffn_output)\n",
        "    ffn_output = LayerNormalization(epsilon=1e-6)(attn_output + ffn_output)\n",
        "    pooling = GlobalAveragePooling1D()(ffn_output)\n",
        "    outputs = Dense(1, activation='sigmoid')(pooling)\n",
        "    \n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer=Adam(learning_rate=rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# 5. Set up Keras Tuner and perform hyperparameter tuning\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=1,\n",
        "    executions_per_trial=1,\n",
        "    directory='sms_spam_tuner',\n",
        "    project_name='sms_spam_transformer'\n",
        ")\n",
        "\n",
        "tuner.search_space_summary()\n",
        "\n",
        "tuner.search(sequences_matrix,y_train, epochs=1, validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])\n",
        "\n",
        "#6. Get the best model and its hyperparameters\n",
        "\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASeL6rvFfPu1",
        "outputId": "c145ed05-51ab-4246-e909-793d899f946f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 4\n",
            "output_dim (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
            "num_heads (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 8, 'step': 2, 'sampling': 'linear'}\n",
            "dff (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 128, 'step': 32, 'sampling': 'linear'}\n",
            "rate (Float)\n",
            "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = best_model.fit(sequences_matrix, y_train, batch_size=32, epochs=1, validation_split=0.2)\n"
      ],
      "metadata": {
        "id": "PxHETWjoMeZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sequences = tok.texts_to_sequences(X_test1)\n",
        "test_sequences_matrix = pad_sequences(test_sequences,maxlen=max_len)\n",
        "y_pred_transformer = best_model.predict(test_sequences_matrix)\n",
        "accr = best_model.evaluate(test_sequences_matrix,y_test1)\n"
      ],
      "metadata": {
        "id": "vT82d9PnPM5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for i in range(len(y_pred_lstm)):\n",
        "  val = [0,0,0]\n",
        "  if y_pred_lstm[i]>=0.5:\n",
        "    val[0] = 1\n",
        "  try:\n",
        "    if y_pred_dnn[i]>=0.5:\n",
        "      val[1] = 1\n",
        "  except: pass  \n",
        "  if y_pred_rnn[i]>=0.5:\n",
        "    val[2] = 1\n",
        "  if val.count(1)>=2:\n",
        "    count = count+1\n",
        "\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "jPDaPZjVUOtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = [\"ham\", \"spam\"]\n",
        "explainer = LimeTextExplainer(class_names = class_names)\n",
        "train_df = df\n",
        "\n",
        "## split to train and val\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=2018)\n",
        "val_df.reset_index(drop=True)\n",
        "\n",
        "## vectorize to tf-idf vectors\n",
        "tfidf_vc = TfidfVectorizer(min_df = 10, max_features = 100000, analyzer = \"word\", ngram_range = (1, 2), stop_words = 'english', lowercase = True)\n",
        "train_vc = tfidf_vc.fit_transform(train_df[\"text\"])\n",
        "val_vc = tfidf_vc.transform(val_df[\"text\"])\n",
        "spam_index = y_test1.index[y_test1 == 1]\n",
        "spam_index = list(spam_index)"
      ],
      "metadata": {
        "id": "Q9I-SBgg9pNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "idx = spam_index[11]\n",
        "model_adv = LogisticRegression(C = 0.5, solver = \"sag\")\n",
        "model_adv = model_adv.fit(train_vc, train_df.target)\n",
        "val_pred = model_adv.predict(val_vc)\n",
        "\n",
        "\n",
        "val_cv = f1_score(val_df.target, val_pred, average = \"binary\")\n",
        "print(val_cv)\n",
        "\n",
        "\n",
        "c = make_pipeline(tfidf_vc, model_adv)\n",
        "class_names = [\"ham\", \"spam\"]\n",
        "explainer = LimeTextExplainer(class_names = class_names)\n",
        "exp = explainer.explain_instance(df[\"text\"][idx], c.predict_proba)\n",
        "exp.as_list()"
      ],
      "metadata": {
        "id": "o0VJQEZU-S-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(idx)\n",
        "X_test1[idx] = \"winner value network custom select receive a reward call claim code valid hour\"\n",
        "test_sequences = tok.texts_to_sequences(X_test1)\n",
        "test_sequences_matrix = pad_sequences(test_sequences,maxlen=max_len)\n",
        "y_pred = model.predict(test_sequences_matrix)\n",
        "y_pred[11]"
      ],
      "metadata": {
        "id": "vvmKls0m_DKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test1 = X_test1.str.replace('call', 'phone')\n",
        "words = X_test1.str.split(expand=True).stack()\n",
        "word_freq = words.value_counts()"
      ],
      "metadata": {
        "id": "5mIApvA3YJeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test1 = X_test1.str.replace('txt', 'text')\n",
        "words = X_test1.str.split(expand=True).stack()\n",
        "word_freq = words.value_counts()\n",
        "word_freq"
      ],
      "metadata": {
        "id": "WmsgUFQ5ZRUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test1 = X_test1.str.replace('å£', ' ')\n",
        "X_test1 = X_test1.str.replace('optin', 'option')\n",
        "X_test1 = X_test1.str.replace('mobilee', 'mobile')\n",
        "X_test1 = X_test1.str.replace('repli', 'reply')\n",
        "X_test1 = X_test1.str.replace('claim', ' ')\n",
        "X_test1 = X_test1.str.replace('servic', 'service')\n",
        "X_test1 = X_test1.str.replace('prize', ' ')\n",
        "words = X_test1.str.split(expand=True).stack()\n",
        "word_freq = words.value_counts()\n",
        "word_freq.head(10)"
      ],
      "metadata": {
        "id": "2CgneaROcIWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test1 = X_test1.str.replace('text', ' ')\n",
        "word_freq.head(20)"
      ],
      "metadata": {
        "id": "xZVG41N2dR3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test1[1044]=\"know someon know deluxe call find\"\n",
        "X_test1[683] = \"hi i am sue year old lapdanc love sex live im bedroom text sue textoper\""
      ],
      "metadata": {
        "id": "3UoVBONRUYJ8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}